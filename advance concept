#Copy data from Database to CSV,Parquet and Avro File Format
Step 1 : Create the tables (Departments & Employees) 
Create Table Departments
(
     ID int primary key,
     Name nvarchar(50),
     Location nvarchar(50)
)
GO

Insert into Departments values (1, 'IT', 'New York')
Insert into Departments values (2, 'HR', 'London')
GO

Create Table Employees
(
     ID int primary key,
     Name nvarchar(50),
     DepartmentID int foreign key references Departments(ID)
)
GO

Insert into Employees values (1, 'Mike', 1)
Insert into Employees values (2, 'John', 1)
Insert into Employees values (3, 'Josh', 1)
Insert into Employees values (4, 'Mary', 2)
Insert into Employees values (5, 'Rosy', 2)
GO

Step 2: Create a new empty asp.net empty web application. Name it ExportData. Add WebForm1.aspx to the project. Copy and paste the following HTML in WebForm1.aspx.
<div style="font-family: Arial">
    Format :
    <asp:DropDownList ID="ddlExportFormat" runat="server">
        <asp:ListItem Text="COMMA DELIMITED" Value="COMMA DELIMITED">
        </asp:ListItem>
        <asp:ListItem Text="PIPE DELIMITED" Value="PIPE DELIMITED">
        </asp:ListItem>
    </asp:DropDownList>
    <asp:Button ID="btnExport" runat="server" Text="Export"
    OnClick="btnExport_Click" />
</div>

Step 3: Copy and paste the following code in WebForm1.aspx.cs
using System;
using System.Configuration;
using System.Data;
using System.Data.SqlClient;
using System.IO;
using System.Text;

namespace ExportData
{
    public partial class WebForm1 : System.Web.UI.Page
    {
        protected void btnExport_Click(object sender, EventArgs e)
        {
            string strDelimiter = ddlExportFormat.SelectedValue == "COMMA DELIMITED"
                                  ? "," : "|";

            string cs = ConfigurationManager.ConnectionStrings["DBCS"].ConnectionString;
            StringBuilder sb = new StringBuilder();
            using (SqlConnection con = new SqlConnection(cs))
            {
                string strQuery = "SELECT [ID] ,[Name],[Location] FROM [Departments];";
                strQuery += "SELECT [ID],[Name],[DepartmentID] FROM [Employees];";

                SqlDataAdapter da = new SqlDataAdapter(strQuery, con);
                DataSet ds = new DataSet();
                da.Fill(ds);

                ds.Tables[0].TableName = "Departments";
                ds.Tables[1].TableName = "Employees";

                foreach (DataRow depratmentDR in ds.Tables["Departments"].Rows)
                {
                    int departmentId = Convert.ToInt32(depratmentDR["ID"]);
                    sb.Append(departmentId.ToString() + strDelimiter);
                    sb.Append(depratmentDR["Name"].ToString() + strDelimiter);
                    sb.Append(depratmentDR["Location"].ToString());
                    sb.Append("\r\n");
                    foreach (DataRow employeeDR in ds.Tables["Employees"]
                        .Select("DepartmentId = '" + departmentId.ToString() + "'"))
                    {
                        sb.Append(employeeDR["ID"].ToString() + strDelimiter);
                        sb.Append(employeeDR["Name"].ToString() + strDelimiter);
                        sb.Append(departmentId.ToString());
                        sb.Append("\r\n");
                    }
                }
            }

            string strFileName = strDelimiter == "," ? "Data.csv" : "Data.txt";

            StreamWriter file = new StreamWriter(@"C:\ExportedData\" + strFileName );
            file.WriteLine(sb.ToString());
            file.Close();
        }
    }
}

Step 4 : Include the connection string in web.config file
<connectionStrings>
  <add name="DBCS"
        connectionString="server=.;database=Sample;integrated security = SSPI"/>
</connectionStrings>

Step 5 : In C:\ drive, create a folder and name it ExportedData.
#2
Create a Data Factory:

Go to the Azure portal.
Select "Create a resource" and then "Data Factory".
Fill in the necessary details and create the Data Factory.
Create a Pipeline in Data Factory:

Go to your Data Factory and open the "Author & Monitor" tool.
Create a new pipeline by clicking on the "+" icon and selecting "Pipeline".
Add a Copy Data Activity:

Drag the "Copy Data" activity from the activities pane to the pipeline canvas.
Configure the source to connect to your database:
Create a new linked service to your database (e.g., Azure SQL Database).
Configure the dataset to point to your specific table.
Configure the sink to save data in different formats (CSV, Parquet, Avro):
Create linked services and datasets for each format using Azure Blob Storage or Azure Data Lake Storage.
Set Up a Schedule Trigger:

Go to the "Triggers" pane and create a new trigger.
Set the trigger type to "Schedule" and configure the schedule (e.g., daily, hourly).
Associate the trigger with your pipeline.
#3

To copy all tables from one database to another using Azure Data Factory (ADF), you can create a data pipeline that dynamically discovers the tables in the source database and then copies each table to the destination database. Here's a step-by-step guide to achieve this:

Step 1: Set Up Linked Services
Create Linked Services:
Go to your Azure Data Factory instance in the Azure portal.
In the left pane, click on "Manage".
Under the "Connections" section, click on "Linked services".
Create a linked service for your source database (e.g., Azure SQL Database, SQL Server, etc.).
Create a linked service for your destination database.
Step 2: Create Datasets
Create Datasets:
Go to the "Author" section in ADF.
Create a dataset for the source database.
Create a dataset for the destination database.
These datasets will be used to define the source and sink in the copy activities.
Step 3: Create a Pipeline
Create a Pipeline:

Go to the "Author" section in ADF.
Click on the "+" icon and select "Pipeline".
Name your pipeline (e.g., "CopyAllTablesPipeline").
Add Activities to the Pipeline:

Lookup Activity:

Add a "Lookup" activity to get the list of tables from the source database.
In the "Settings" tab of the Lookup activity, configure the source dataset and write a query to get the list of tables (e.g., SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE').
ForEach Activity:

Add a "ForEach" activity to iterate over the list of tables returned by the Lookup activity.
In the "Settings" tab of the ForEach activity, set the "Items" field to the output of the Lookup activity.
Inside the ForEach activity, add a "Copy Data" activity to copy each table.
Copy Data Activity:

Inside the "ForEach" activity, add a "Copy Data" activity.
Configure the "Source" tab to use the source dataset and set the table name dynamically using a parameter (e.g., @item().TABLE_NAME).
Configure the "Sink" tab to use the destination dataset and set the table name dynamically using the same parameter (e.g., @item().TABLE_NAME).
Step 4: Parameterize the Pipeline
Add Parameters to the Pipeline:

In the "Parameters" section of the pipeline, add a parameter for the table name (e.g., "TableName").
Configure the Lookup Activity:

In the "Settings" tab of the Lookup activity, set the query to something like SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE'.
Configure the ForEach Activity:

In the "Items" field of the ForEach activity, set it to @activity('LookupActivity').output.value.
Configure the Copy Data Activity:

In the "Source" tab, set the table name to @item().TABLE_NAME.
In the "Sink" tab, set the table name to @item().TABLE_NAME.
Step 5: Test and Run the Pipeline
Test the Pipeline:

Save and debug the pipeline to ensure it works correctly.
Check for any errors and resolve them.
Run the Pipeline:

Once you have verified that the pipeline works as expected, trigger it to run.
#4
Step 1: Set Up Linked Services
Create Linked Services:
In the Azure Data Factory (ADF) portal, go to the "Manage" section.
Under the "Connections" section, click on "Linked services".
Create a linked service for your source database (e.g., Azure SQL Database, SQL Server).
Create a linked service for your destination database.
Step 2: Create Datasets
Create Datasets:
Go to the "Author" section in ADF.
Create a dataset for the source database.
Create a dataset for the destination database.
These datasets will be used to define the source and sink in the copy activities.
Step 3: Define the List of Tables and Columns
Define the Tables and Columns:
Prepare a JSON file or use a Lookup activity to define the list of tables and their respective columns that you want to copy.
Example JSON structure for tables and columns:
json
Copy code
[
  {
    "tableName": "Table1",
    "columns": ["Column1", "Column2"]
  },
  {
    "tableName": "Table2",
    "columns": ["ColumnA", "ColumnB"]
  }
]
Step 4: Create a Pipeline
Create a Pipeline:

Go to the "Author" section in ADF.
Click on the "+" icon and select "Pipeline".
Name your pipeline (e.g., "CopySelectiveTablesPipeline").
Add Activities to the Pipeline:

Lookup Activity:

Add a "Lookup" activity to get the list of tables and columns from the JSON file or a database table.
In the "Settings" tab of the Lookup activity, configure the source dataset and write a query or point to the JSON file containing the list of tables and columns.
ForEach Activity:

Add a "ForEach" activity to iterate over the list of tables returned by the Lookup activity.
In the "Settings" tab of the ForEach activity, set the "Items" field to the output of the Lookup activity.
Inside the ForEach activity, add a "Copy Data" activity to copy each table with the specified columns.
Copy Data Activity:

Inside the "ForEach" activity, add a "Copy Data" activity.
Configure the "Source" tab to use the source dataset and dynamically set the table name and columns using parameters.
Configure the "Sink" tab to use the destination dataset and set the table name dynamically using the same parameters.
Step 5: Parameterize the Pipeline
Add Parameters to the Pipeline:

In the "Parameters" section of the pipeline, add parameters for the table name and columns (e.g., "TableName" and "Columns").
Configure the Lookup Activity:

In the "Settings" tab of the Lookup activity, set the query to fetch the list of tables and columns.
Configure the ForEach Activity:

In the "Items" field of the ForEach activity, set it to @activity('LookupTables').output.value.
Configure the Copy Data Activity:

In the "Source" tab, set the table name and columns to @item().tableName and @item().columns.
